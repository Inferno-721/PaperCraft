{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a0fe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.15\n"
     ]
    }
   ],
   "source": [
    "# Import required modules and initialize the builder from open_deep_research\n",
    "import uuid \n",
    "import os, getpass\n",
    "import open_deep_research   \n",
    "print(open_deep_research.__version__) \n",
    "from IPython.display import Image, display, Markdown\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from open_deep_research.graph import builder\n",
    "import requests\n",
    "import json\n",
    "from typing import Dict, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83bc2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d84fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "# _set_env(\"ANTHROPIC_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "_set_env(\"GROQ_API_KEY\")\n",
    "# _set_env(\"PERPLEXITY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7181f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_search_results(query: str, max_results: int = 3) -> List[Dict[str, Any]]:\n",
    "#     \"\"\"Get search results from Tavily API directly\"\"\"\n",
    "#     tavily_api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "#     if not tavily_api_key:\n",
    "#         raise ValueError(\"TAVILY_API_KEY is not set in environment variables\")\n",
    "        \n",
    "#     search_url = \"https://api.tavily.com/search\"\n",
    "#     search_params = {\n",
    "#         \"api_key\": tavily_api_key,\n",
    "#         \"query\": query,\n",
    "#         \"search_depth\": \"deep\",\n",
    "#         \"max_results\": max_results\n",
    "#     }\n",
    "    \n",
    "#     try:\n",
    "#         search_response = requests.post(search_url, json=search_params)\n",
    "#         search_response.raise_for_status()  # Raise exception for HTTP errors\n",
    "#         search_data = search_response.json()\n",
    "        \n",
    "#         if \"results\" in search_data:\n",
    "#             results = search_data[\"results\"]\n",
    "#             for i, res in enumerate(results):\n",
    "#                 print(f\"Result {i+1} Date: {res.get('published_date', 'No date field')}\")\n",
    "#             return results\n",
    "#         else:\n",
    "#             print(f\"Unexpected search response format: {search_data}\")\n",
    "#             return []\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Search API error: {str(e)}\")\n",
    "#         return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da5dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(query: str, max_results: int = 3) -> List[Dict[str, Any]]:\n",
    "    tavily_api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "    if not tavily_api_key:\n",
    "        raise ValueError(\"TAVILY_API_KEY is not set in environment variables\")\n",
    "        \n",
    "    search_url = \"https://api.tavily.com/search\"\n",
    "    search_params = {\n",
    "        \"api_key\": tavily_api_key,\n",
    "        \"query\": query,\n",
    "        \"search_depth\": \"basic\",\n",
    "        \"max_results\": max_results\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_response = requests.post(search_url, json=search_params)\n",
    "        search_response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        search_data = search_response.json()\n",
    "        \n",
    "        results = search_data.get(\"results\", [])\n",
    "        if results:\n",
    "            for i, res in enumerate(results, 1):\n",
    "                date = res.get(\"published_date\") or res.get(\"date\") or \"No date available\"\n",
    "                print(f\"Result {i} Date: {date}\")\n",
    "            return results\n",
    "        else:\n",
    "            print(\"Unexpected search response format:\", search_data)\n",
    "            return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Search API error: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84e99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(search_results: List[Dict[str, Any]], topic: str) -> str:\n",
    "    \"\"\"Generate report using Groq API directly\"\"\"\n",
    "    groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "    if not groq_api_key:\n",
    "        raise ValueError(\"GROQ_API_KEY is not set in environment variables\")\n",
    "        \n",
    "    groq_url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    groq_headers = {\n",
    "        \"Authorization\": f\"Bearer {groq_api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Format search results for the prompt\n",
    "    formatted_results = \"\"\n",
    "    for i, result in enumerate(search_results, 1):\n",
    "        title = result.get(\"title\", \"Untitled Source\")\n",
    "        url = result.get(\"url\", \"No URL provided\")\n",
    "        content_snippet = result.get(\"content\", \"\")[:200]  # First 200 chars of content\n",
    "        formatted_results += f\"Source {i}: {title}\\nURL: {url}\\nExcerpt: {content_snippet}...\\n\\n\"\n",
    "    \n",
    "    # Create a more structured prompt\n",
    "    prompt = f\"\"\"Based on these search results about {topic}, create a concise report following this structure:\n",
    "\n",
    "1. Introduction (20 sentences)\n",
    "   - Brief overview of {topic}\n",
    "\n",
    "2. Key Concepts (34 bullet points)\n",
    "   - Main ideas related to {topic}\n",
    "\n",
    "3. Applications or Implications (23 sentences)\n",
    "   - How {topic} is being used or its importance\n",
    "\n",
    "4. Summary Table or List\n",
    "   - A concise summary of the main points\n",
    "\n",
    "SEARCH RESULTS:\n",
    "{formatted_results}\n",
    "\n",
    "Keep your total response under 300 lines.\"\"\"\n",
    "    \n",
    "    groq_data = {\n",
    "        \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",  # Updated to use a more capable model\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You create concise, factual reports based on provided search results.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.3\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        groq_response = requests.post(groq_url, headers=groq_headers, json=groq_data)\n",
    "        groq_response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        groq_data = groq_response.json()\n",
    "        \n",
    "        if \"choices\" in groq_data and len(groq_data[\"choices\"]) > 0:\n",
    "            result = groq_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "            return result\n",
    "        else:\n",
    "            error_msg = f\"Unexpected Groq API response: {groq_data}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"Groq API error: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26078110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for information about 'NLP'...\n",
      "Result 1 Date: No date available\n",
      "Result 2 Date: No date available\n",
      "Result 3 Date: No date available\n",
      "Found 3 search results. Generating report...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Report on NLP\n",
       "\n",
       "**Introduction**\n",
       "\n",
       "Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It is a rapidly growing area of AI, with applications in text generators, chatbots, and more. NLP enables computers to understand, interpret, and generate human language, allowing humans to communicate with machines more effectively. The field of NLP has gained significant attention in recent years due to the increasing amount of text data available from social media, websites, and other sources. This has led to the development of various NLP techniques and tools that can analyze, understand, and generate human language. NLP has numerous applications in areas such as customer service, language translation, and text summarization. The goal of NLP is to enable computers to process and understand human language, allowing for more efficient and effective communication between humans and machines. NLP combines computer science, linguistics, and cognitive psychology to achieve this goal. With the growing amount of text data, NLP is becoming a key tool to gain insights and automate tasks. NLP has the potential to revolutionize the way humans interact with machines. It is an interdisciplinary field that requires expertise in computer science, linguistics, and cognitive psychology. NLP has many applications in industries such as healthcare, finance, and education. The field of NLP is rapidly evolving, with new techniques and tools being developed continuously. NLP has the potential to transform the way we interact with machines. It is an exciting and rapidly growing field. NLP has many challenges, including dealing with ambiguity and uncertainty in human language. Despite these challenges, NLP has many applications in areas such as sentiment analysis and text classification. NLP is a key technology for the development of intelligent systems. \n",
       "\n",
       "**Key Concepts**\n",
       "\n",
       "* Tokenization\n",
       "* Part-of-speech tagging\n",
       "* Named entity recognition\n",
       "* Dependency parsing\n",
       "* Sentiment analysis\n",
       "* Text classification\n",
       "* Language modeling\n",
       "* Machine translation\n",
       "* Text generation\n",
       "* Dialogue systems\n",
       "* Question answering\n",
       "* Information retrieval\n",
       "* Text summarization\n",
       "* Coreference resolution\n",
       "* Discourse analysis\n",
       "* Pragmatics\n",
       "* Semantics\n",
       "* Syntax\n",
       "* Morphology\n",
       "* Lexicon\n",
       "* Corpus linguistics\n",
       "* Deep learning\n",
       "* Neural networks\n",
       "* Word embeddings\n",
       "* Language transfer\n",
       "* Adversarial training\n",
       "* Attention mechanisms\n",
       "* Transformers\n",
       "* BERT\n",
       "* RoBERTa\n",
       "* XLNet\n",
       "* Natural language understanding\n",
       "* Natural language generation\n",
       "* Human-computer interaction\n",
       "* Human language\n",
       "* Linguistic analysis\n",
       "* Computational linguistics\n",
       "* Statistical NLP\n",
       "* Hybrid NLP\n",
       "\n",
       "**Applications or Implications**\n",
       "\n",
       "NLP has numerous applications in areas such as customer service, language translation, and text summarization. It is being used to develop chatbots that can understand and respond to customer inquiries. NLP is also being used in sentiment analysis to analyze customer feedback and sentiment. It is being used in language translation to translate text from one language to another. NLP has applications in healthcare, finance, and education. It is being used to analyze medical text and diagnose diseases. NLP is being used to develop intelligent systems that can understand and respond to human language. It has the potential to revolutionize the way humans interact with machines. NLP has many implications for industries such as customer service, marketing, and sales. It is being used to develop more efficient and effective communication systems. NLP has the potential to improve human-computer interaction. It is being used to develop more intelligent and responsive machines. NLP has many applications in areas such as information retrieval and text classification. \n",
       "\n",
       "**Summary Table or List**\n",
       "\n",
       "| **Category** | **Key Points** |\n",
       "| --- | --- |\n",
       "| **Introduction** | NLP, AI, human language |\n",
       "| **Key Concepts** | 17 concepts, including tokenization, sentiment analysis, and machine translation |\n",
       "| **Applications** | Customer service, language translation, text summarization, healthcare, finance, education |\n",
       "| **Implications** | Improved human-computer interaction, more efficient communication systems, intelligent systems |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Sources\n",
       "\n",
       "1. [Natural Language Processing (NLP) [A Complete Guide] - DeepLearning.AI](https://www.deeplearning.ai/resources/natural-language-processing/)\n",
       "2. [What is Natural Language Processing (NLP)? A Beginner's Guide](https://www.datacamp.com/blog/what-is-natural-language-processing)\n",
       "3. [Natural Language Processing (NLP) - Overview | GeeksforGeeks](https://www.geeksforgeeks.org/natural-language-processing-overview/)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# def set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# # Set necessary API keys\n",
    "# set_env(\"TAVILY_API_KEY\")\n",
    "# set_env(\"GROQ_API_KEY\")\n",
    "\n",
    "# Main execution function\n",
    "def run_research(topic: str, search_query: str = None):\n",
    "    \"\"\"Run the research pipeline for a given topic\"\"\"\n",
    "    if search_query is None:\n",
    "        search_query = f\"{topic} explanation concepts applications\"\n",
    "        \n",
    "    print(f\"Searching for information about '{topic}'...\")\n",
    "    search_results = get_search_results(search_query, max_results=3)\n",
    "\n",
    "    if search_results:\n",
    "        print(f\"Found {len(search_results)} search results. Generating report...\")\n",
    "        report = generate_report(search_results, topic)\n",
    "        display(Markdown(f\"# Report on {topic}\\n\\n{report}\"))\n",
    "        \n",
    "        # Display sources\n",
    "        sources_md = \"## Sources\\n\\n\"\n",
    "        for i, result in enumerate(search_results, 1):\n",
    "            title = result.get(\"title\", \"Untitled\")\n",
    "            url = result.get(\"url\", \"#\")\n",
    "            sources_md += f\"{i}. [{title}]({url})\\n\"\n",
    "        \n",
    "        display(Markdown(sources_md))\n",
    "    else:\n",
    "        print(\"No search results found. Please check your Tavily API key and try again.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    run_research(\"NLP\", search_query=\"nlp explanation concepts applications\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meraenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
